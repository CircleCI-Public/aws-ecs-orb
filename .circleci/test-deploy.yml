version: 2.1
orbs:
  aws-ecs: circleci/aws-ecs@dev:<<pipeline.git.revision>>
  orb-tools: circleci/orb-tools@11.1
  aws-cli: circleci/aws-cli@3.1
  jq: circleci/jq@2.2

filters: &filters
  tags:
    only: /.*/
jobs:
  pytest:
    docker:
      - image: cimg/python:3.10.4
    steps:
      - checkout
      - restore_cache:
          keys:
            - cache-{{ checksum "Pipfile.lock" }}
      - run:
          name: Install Python dependencies
          command: |
            pipenv sync --dev
      - run:
          name: Run unit tests
          command: |
            cd src/scripts
            pipenv run pylint --py3k *.py
            pipenv run coverage run --source . -m pytest
            pipenv run coverage report --omit "*/test*"
      - save_cache:
          key: cache-{{ checksum "Pipfile.lock" }}
          paths:
            - ~/.local
            - ~/.cache
  test-fargatespot:
    docker:
      - image: cimg/base:stable
    parameters:
      profile-name:
        type: string
        default: 'default'
      role-arn:
        type: string
        default: ''  
    steps:
      - aws-cli/setup:
          profile-name: << parameters.profile-name >>
          role-arn: << parameters.role-arn >>
      - jq/install
      - run:
          name: Get cluster info
          command: |
            SERVICES_OBJ=$(aws ecs describe-services --cluster "${AWS_RESOURCE_NAME_PREFIX_FARGATE}-cluster" --services "${AWS_RESOURCE_NAME_PREFIX_FARGATE}-service")
            VPC_CONF_OBJ=$(echo $SERVICES_OBJ | jq '.services[].networkConfiguration.awsvpcConfiguration')
            SUBNET_ONE=$(echo "$VPC_CONF_OBJ" |  jq '.subnets[0]')
            SUBNET_TWO=$(echo "$VPC_CONF_OBJ" |  jq '.subnets[1]')
            SECURITY_GROUP_IDS=$(echo "$VPC_CONF_OBJ" |  jq '.securityGroups[0]')
            CLUSTER_NAME=$(echo "$SERVICES_OBJ" |  jq '.services[].clusterArn')
            echo "export SUBNET_ONE=$SUBNET_ONE" >> $BASH_ENV
            echo "export SUBNET_TWO=$SUBNET_TWO" >> $BASH_ENV
            echo "export SECURITY_GROUP_IDS_FETCHED=$SECURITY_GROUP_IDS_FETCHED" >> $BASH_ENV
            echo "export CLUSTER_NAME=$CLUSTER_NAME" >> $BASH_ENV
      - run:
          name: Associate cluster
          command: |
            aws ecs put-cluster-capacity-providers \
              --cluster "${AWS_RESOURCE_NAME_PREFIX_FARGATE}-cluster" \
              --capacity-providers FARGATE FARGATE_SPOT  \
              --default-capacity-provider-strategy capacityProvider=FARGATE,weight=1 \
              --region ${AWS_REGION}
      - run:
          name: Register task definition
          command: |
            aws ecs register-task-definition \
              --family ecs-orb-fgs-1-sleep360 \
              --cpu 256 --memory 512 \
              --requires-compatibilities FARGATE \
              --network-mode awsvpc \
              --container-definitions "[{\"name\":\"sleep\",\"image\":\"busybox\",\"command\":[\"sleep\",\"360\"],\"memory\":256,\"essential\":true}]"
      - aws-ecs/run-task:
          cluster: $CLUSTER_NAME
          capacity-provider-strategy: capacityProvider=FARGATE,weight=1 capacityProvider=FARGATE_SPOT,weight=1
          launch-type: ""
          task-definition: ecs-orb-fgs-1-sleep360
          subnet-ids: '$SUBNET_ONE, $SUBNET_TWO'
          security-group-ids: $SECURITY_GROUP_IDS_FETCHED
  build-test-app:
    docker:
      - image: cimg/go:1.19
    parameters:
      docker-image-namespace:
        description: "The namespace in which the built Docker image will be published"
        type: string
      docker-image-name:
        description: "The name for the built Docker image"
        type: string
    steps:
      - checkout
      - setup_remote_docker
      - run:
          name: Make the executable
          command: |
            cd tests/test_app
            go build -o demo-app src/main.go
      - run:
          name: Build image
          command: |
            cd tests/test_app
            docker build -t <<parameters.docker-image-namespace>>/<<parameters.docker-image-name>> .
      - run:
          name: Test image
          command: |
            docker run -d -p 8080:8080 --name built-image <<parameters.docker-image-namespace>>/<<parameters.docker-image-name>>
            sleep 10
            docker run --network container:built-image appropriate/curl --retry 10 --retry-connrefused http://localhost:8080 | grep "Hello World!"
      - run:
          name: Save image to an archive
          command: |
            mkdir -p docker-images/<<parameters.docker-image-name>>
            docker save -o docker-images/<<parameters.docker-image-name>>/<<parameters.docker-image-name>>.tar <<parameters.docker-image-namespace>>/<<parameters.docker-image-name>>
      - persist_to_workspace:
          root: .
          paths:
            - docker-images
  set-up-test-env:
    parameters:
      terraform-image:
        type: string
        default: "hashicorp/terraform:1.1.9"
      aws-resource-name-prefix:
        type: string
      terraform-config-dir:
        type: string
      profile-name:
        type: string
        default: 'default'
      role-arn:
        type: string
        default: ''
      aws-access-key-id:
        type: env_var_name
        default: AWS_ACCESS_KEY_ID
      aws-secret-access-key:
        type: env_var_name
        default: AWS_SECRET_ACCESS_KEY
      
    docker:
      - image: << parameters.terraform-image >>
    steps:
      - run:
          name: Check if test env should be set up
          command: |
            if [ "${SKIP_TEST_ENV_CREATION}" = "1" ]
            then
              circleci step halt
            fi
      - checkout
      - when: 
          condition: << parameters.role-arn >>
          steps:
            - aws-cli/setup:
                profile-name: << parameters.profile-name >>
                role-arn: << parameters.role-arn >>
      - run:
          name: terraform init
          command: |
            cd << parameters.terraform-config-dir >>
            terraform init -input=false
      - run:
          name: terraform plan
          command: |
            cd << parameters.terraform-config-dir >>
            terraform plan \
                -input=false \
                -var "aws_access_key=${AWS_ACCESS_KEY_ID}" \
                -var "aws_secret_key=${AWS_SECRET_ACCESS_KEY}" \
                -var "aws_session_token=${AWS_SESSION_TOKEN}" \
                -var "aws_region=${AWS_REGION}" \
                -var "aws_account_id=${AWS_ACCOUNT_ID}" \
                -var "aws_resource_prefix=<< parameters.aws-resource-name-prefix >>" \
                -out tfplan
      - run:
          name: terraform apply
          command: |
            cd << parameters.terraform-config-dir >>
            terraform apply -input=false -auto-approve tfplan
  test-service-update:
    docker:
      - image: cimg/python:3.10.4
    parameters:
      aws-resource-name-prefix:
        description: "Prefix that the AWS resources for this launch type share"
        type: string
      family-name:
        description: "Family name"
        type: string
      service-name:
        description: "Service name"
        type: string
      docker-image-namespace:
        description: "The namespace in which the Docker image was published"
        type: string
      docker-image-name:
        description: "The name for the previously built Docker image"
        type: string
      skip-service-update:
        description: "Skip updating the ECS service"
        type: boolean
        default: false
      profile-name:
        description: "The profile name to use for AWS credentials"
        type: string
        default: "default"
      role-arn:
        type: string
        default: ''
    steps:
      - checkout
      - setup_remote_docker
      - attach_workspace:
          at: workspace
      - aws-cli/setup:
          profile-name: << parameters.profile-name >>
          role-arn: << parameters.role-arn >>
      - run:
          name: Load image
          command: |
            docker load --input workspace/docker-images/<<parameters.docker-image-name>>/<<parameters.docker-image-name>>.tar
      - run:
          name: Setup common environment variables
          command: |
            echo 'export ECR_REPOSITORY_NAME="<< parameters.aws-resource-name-prefix >>"' >> $BASH_ENV
            echo 'export ECS_CLUSTER_NAME="<< parameters.aws-resource-name-prefix >>-cluster"' >> $BASH_ENV
            echo 'export ECS_SERVICE_NAME="<< parameters.aws-resource-name-prefix >>-service"' >> $BASH_ENV
            echo 'export FULL_IMAGE_NAME="${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPOSITORY_NAME}:${CIRCLE_SHA1}"' >> $BASH_ENV
      - run:
          name: Push image
          command: |
            aws ecr get-login-password --region $AWS_REGION --profile "<<parameters.profile-name>>" | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com
            docker push $FULL_IMAGE_NAME
      - unless:
          condition: << parameters.skip-service-update >>
          steps:
            - aws-cli/setup:
                profile-name: << parameters.profile-name >>
                role-arn: << parameters.role-arn >>          
            - aws-ecs/update-service:
                family: "<< parameters.family-name >>"
                service-name: "<< parameters.service-name >>"
                cluster: "<< parameters.aws-resource-name-prefix >>-cluster"
                container-image-name-updates: "container=<< parameters.aws-resource-name-prefix >>-service,image-and-tag=$FULL_IMAGE_NAME"
                container-env-var-updates: 'container=<< parameters.aws-resource-name-prefix >>-service,name=VERSION_INFO,value="${CIRCLE_SHA1}_${CIRCLE_BUILD_NUM}",container=<< parameters.aws-resource-name-prefix >>-service,name=BUILD_DATE,value=$(date)'
                verify-revision-is-deployed: true
                fail-on-verification-timeout: false
                profile-name: "<<parameters.profile-name>>"
            - test-deployment:
                service-name: "<< parameters.aws-resource-name-prefix >>-service"
                cluster: "<< parameters.aws-resource-name-prefix >>-cluster"
  test-task-definition-update:
    docker:
      - image: cimg/python:3.10.4
    parameters:
      family-name:
        description: "Family name"
        type: string
      profile-name:
        type: string
        default: 'default'
      role-arn:
        type: string
        default: ''    
    steps:
      - checkout
      - aws-cli/setup:
          profile-name: << parameters.profile-name >>
          role-arn: << parameters.role-arn >>
          aws-region: AWS_REGION
      - run:
          name: Get existing task definition
          command: |
            aws ecs describe-task-definition --task-definition << parameters.family-name >> \
              | jq '.taskDefinition' | jq '.memory = "3072"' \
              | jq 'del(.["taskDefinitionArn", "revision", "status", "requiresAttributes", "compatibilities", "registeredAt", "registeredBy"])' \
              > task-definition.json
      - aws-ecs/update-task-definition-from-json:
          task-definition-json: "task-definition.json"
      - run:
          name: Check if task definition was updated
          command: |
            aws ecs describe-task-definition --task-definition << parameters.family-name >> --include TAGS | grep "3072"
  set-up-run-task-test:
    docker:
      - image: cimg/python:3.10.4
    parameters:
      family-name:
        description: "Family name"
        type: string
      profile-name:
        description: "The profile name to use for AWS credentials"
        type: string
        default: "default"
      role-arn:
        type: string
        default: ''        
    steps:
      - checkout
      - aws-cli/setup:
          role-arn: << parameters.role-arn >>
          profile-name: << parameters.profile-name >>
          aws-region: AWS_REGION
      - run:
          name: Register task definition
          command: |
            aws ecs register-task-definition \
              --family << parameters.family-name >> \
              --cpu 256 --memory 512 \
              --container-definitions "[{\"name\":\"sleep\",\"image\":\"busybox\",\"command\":[\"sleep\",\"360\"],\"memory\":256,\"essential\":true}]"
  tear-down-run-task-test:
    docker:
      - image: cimg/python:3.10.4
    parameters:
      family-name:
        description: "Family name"
        type: string
      profile-name:
        type: string
        default: 'default'
      role-arn:
        type: string
        default: ''            
    steps:
      - checkout
      - aws-cli/setup:
          profile-name: << parameters.profile-name >>
          role-arn: << parameters.role-arn >>
          aws-region: AWS_REGION
      - run:
          name: Deregister task definition
          command: |
            TASK_DEFINITION_ARN=$(aws ecs describe-task-definition \
              --task-definition << parameters.family-name >> | jq -r '.taskDefinition.taskDefinitionArn')
            aws ecs deregister-task-definition --task-definition ${TASK_DEFINITION_ARN}
  tear-down-test-env:
    parameters:
      terraform-image:
        type: string
        default: hashicorp/terraform:1.1.9
      aws-resource-name-prefix:
        type: string
      terraform-config-dir:
        type: string
      aws-access-key-id:
        type: env_var_name
        default: AWS_ACCESS_KEY_ID
      aws-secret-access-key:
        type: env_var_name
        default: AWS_SECRET_ACCESS_KEY
      profile-name:
        type: string
        default: 'default'
      role-arn:
        type: string
        default: ''
    docker:
      - image: << parameters.terraform-image >>
    steps:
      - run:
          name: Check if test env should be destroyed
          command: |
            if [ "${SKIP_TEST_ENV_TEARDOWN}" = "1" ]
            then
              circleci step halt
            fi
      - checkout
      - when: 
          condition: << parameters.role-arn >>
          steps:
            - aws-cli/setup:
                profile-name: << parameters.profile-name >>
                role-arn: << parameters.role-arn >>   
      - run:
          name: terraform init
          command: |
            cd << parameters.terraform-config-dir >>
            terraform init -input=false
      - run:
          name: Tear down test environment
          no_output_timeout: "20m"
          command: |-
            cd << parameters.terraform-config-dir >>
            if [ "$(terraform destroy -input=false -auto-approve \
                -var "aws_access_key=${AWS_ACCESS_KEY_ID}" \
                -var "aws_secret_key=${AWS_SECRET_ACCESS_KEY}" \
                -var "aws_session_token=${AWS_SESSION_TOKEN}" \
                -var "aws_region=${AWS_DEFAULT_REGION}" \
                -var "aws_account_id=${AWS_ACCOUNT_ID}" \
                -var "aws_resource_prefix=<< parameters.aws-resource-name-prefix >>" > /dev/null; echo $?)" -ne 0 ]; then

                echo "Retrying terraform destroy"
                terraform destroy -input=false -auto-approve \
                  -var "aws_access_key=${AWS_ACCESS_KEY_ID}" \
                  -var "aws_secret_key=${AWS_SECRET_ACCESS_KEY}" \
                  -var "aws_region=${AWS_DEFAULT_REGION}" \
                  -var "aws_account_id=${AWS_ACCOUNT_ID}" \
                  -var "aws_resource_prefix=<< parameters.aws-resource-name-prefix >>"
            fi
  integration-test-ecs-cli-install:
    parameters:
      executor:
        type: executor
      version:
        description: Select a specific version of the AWS ECS CLI. By default the latest version will be used.
        default: latest
        type: string
      install-dir:
        type: string
        default: "/usr/local/bin/ecs-cli"
        description: |
          Specify the installation directory
      override-installed:
        type: boolean
        default: false
        description: Enable this to override the installed version and install your specified version.
    executor: <<parameters.executor>>
    steps:
      - aws-ecs/install-ecs-cli:
          version: <<parameters.version>>
          install-dir: <<parameters.install-dir>>
          override-installed: <<parameters.override-installed>>
workflows:
  test-deploy:
    jobs:
      # Make sure to include "filters: *filters" in every test job you want to run as part of your deployment.
      - integration-test-ecs-cli-install:
          version: "v1.9.0"
          matrix:
            parameters:
              executor: [linux, mac]
          filters: *filters
      # #################
      # # Fargate
      # #################
      - build-test-app:
          name: fargate_build-test-app
          docker-image-namespace: "${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          docker-image-name: "${AWS_RESOURCE_NAME_PREFIX_FARGATE}:${CIRCLE_SHA1}"
          context: [CPE-OIDC]
          filters: *filters
      - set-up-test-env:
          name: fargate_set-up-test-env
          filters: *filters
          requires:
            - fargate_build-test-app
          aws-resource-name-prefix: ${AWS_RESOURCE_NAME_PREFIX_FARGATE}
          terraform-config-dir: "tests/terraform_setup/fargate"
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
      - test-service-update:
          name: fargate_test-update-service-command
          filters: *filters
          requires:
            - fargate_set-up-test-env
          aws-resource-name-prefix: ${AWS_RESOURCE_NAME_PREFIX_FARGATE}
          family-name: "${AWS_RESOURCE_NAME_PREFIX_FARGATE}-service"
          service-name: "${AWS_RESOURCE_NAME_PREFIX_FARGATE}-service"
          docker-image-namespace: "${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          docker-image-name: "${AWS_RESOURCE_NAME_PREFIX_FARGATE}:${CIRCLE_SHA1}"
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
      - aws-ecs/deploy-service-update:
          name: fargate_test-update-service-job
          docker-image-for-job: cimg/python:3.10.4
          filters: *filters
          requires:
            - fargate_test-update-service-command
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-region: AWS_REGION
          profile-name: "ECS_TEST_PROFILE"
          family: "${AWS_RESOURCE_NAME_PREFIX_FARGATE}-service"
          cluster: "${AWS_RESOURCE_NAME_PREFIX_FARGATE}-cluster"
          container-env-var-updates: 'container=${AWS_RESOURCE_NAME_PREFIX_FARGATE}-service,name=VERSION_INFO,value="${CIRCLE_SHA1}_${CIRCLE_BUILD_NUM}",container=${AWS_RESOURCE_NAME_PREFIX_FARGATE}-service,name=BUILD_DATE,value=$(date)'
          # test the force-new-deployment flag
          force-new-deployment: true
          verify-revision-is-deployed: true
          max-poll-attempts: 40
          poll-interval: 10
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
          post-steps:
            - test-deployment:
                service-name: "${AWS_RESOURCE_NAME_PREFIX_FARGATE}-service"
                cluster: "${AWS_RESOURCE_NAME_PREFIX_FARGATE}-cluster"
      - aws-ecs/deploy-service-update:
          name: fargate_test-update-service-skip-registration
          docker-image-for-job: cimg/python:3.10.4
          filters: *filters
          requires:
            - fargate_test-update-service-job
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-region: AWS_REGION
          profile-name: "ECS_TEST_PROFILE"
          family: "${AWS_RESOURCE_NAME_PREFIX_FARGATE}-service"
          cluster: "${AWS_RESOURCE_NAME_PREFIX_FARGATE}-cluster"
          # test skipping registration of a new task definition
          skip-task-definition-registration: true
          # test the enable-circuit-breaker flag
          enable-circuit-breaker: true
          verify-revision-is-deployed: true
          max-poll-attempts: 40
          poll-interval: 10
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
      - tear-down-test-env:
          name: fargate_tear-down-test-env
          filters: *filters
          requires:
            - fargate_test-update-service-skip-registration
            - test-fargatespot
          aws-resource-name-prefix: ${AWS_RESOURCE_NAME_PREFIX_FARGATE}
          terraform-config-dir: "tests/terraform_setup/fargate"
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"

      # #################
      # # EC2
      # #################
      - build-test-app:
          name: ec2_build-test-app
          docker-image-namespace: "${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          docker-image-name: "${AWS_RESOURCE_NAME_PREFIX_EC2}:${CIRCLE_SHA1}"
          context: [CPE-OIDC]
          filters: *filters
      - set-up-test-env:
          name: ec2_set-up-test-env
          filters: *filters
          requires:
            - ec2_build-test-app
          aws-resource-name-prefix: ${AWS_RESOURCE_NAME_PREFIX_EC2}
          terraform-config-dir: "tests/terraform_setup/ec2"
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
      - set-up-run-task-test:
          name: ec2_set-up-run-task-test
          filters: *filters
          requires:
            - ec2_set-up-test-env
          family-name: "${AWS_RESOURCE_NAME_PREFIX_EC2}-sleep360"
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
      - aws-ecs/run-task:
          name: ec2_run-task-test
          filters: *filters
          requires:
            - ec2_set-up-run-task-test
          cluster: "${AWS_RESOURCE_NAME_PREFIX_EC2}-cluster"
          aws-region: AWS_REGION
          task-definition: "${AWS_RESOURCE_NAME_PREFIX_EC2}-sleep360"
          launch-type: "EC2"
          awsvpc: false
          run-task-output: "run-task-output.json"
          overrides: '{"containerOverrides":[{"name": "${INTERPOLATION_TEST}", "memory": 512}]}'
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
      - tear-down-run-task-test:
          name: ec2_tear-down-run-task-test
          filters: *filters
          requires:
            - ec2_run-task-test
          family-name: ${AWS_RESOURCE_NAME_PREFIX_EC2}-sleep360
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
      - test-service-update:
          name: ec2_test-update-service-command
          filters: *filters
          requires:
            - ec2_set-up-test-env
          aws-resource-name-prefix: ${AWS_RESOURCE_NAME_PREFIX_EC2}
          family-name: "${AWS_RESOURCE_NAME_PREFIX_EC2}-family"
          service-name: "${AWS_RESOURCE_NAME_PREFIX_EC2}-service"
          docker-image-namespace: "${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          docker-image-name: "${AWS_RESOURCE_NAME_PREFIX_EC2}:${CIRCLE_SHA1}"
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
      - test-task-definition-update:
          name: ec2_test-task-definition-update
          family-name: "${AWS_RESOURCE_NAME_PREFIX_EC2}-family"
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
          filters: *filters
          requires:
            - ec2_test-update-service-command
      - aws-ecs/deploy-service-update:
          name: ec2_test-update-service-job
          docker-image-for-job: cimg/python:3.10.4
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
          filters: *filters
          requires:
            - ec2_test-task-definition-update
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-region: AWS_REGION
          family: "${AWS_RESOURCE_NAME_PREFIX_EC2}-family"
          service-name: "${AWS_RESOURCE_NAME_PREFIX_EC2}-service"
          cluster: "${AWS_RESOURCE_NAME_PREFIX_EC2}-cluster"
          container-env-var-updates: 'container=${AWS_RESOURCE_NAME_PREFIX_EC2}-service,name=VERSION_INFO,value="Asterisk * expansion test ${CIRCLE_SHA1}_${CIRCLE_BUILD_NUM}",container=${AWS_RESOURCE_NAME_PREFIX_EC2}-service,name=BUILD_DATE,value=$(date)'
          verify-revision-is-deployed: true
          fail-on-verification-timeout: false
          post-steps:
            - test-deployment:
                service-name: "${AWS_RESOURCE_NAME_PREFIX_EC2}-service"
                cluster: "${AWS_RESOURCE_NAME_PREFIX_EC2}-cluster"
                test-asterisk-expansion: true
      - tear-down-test-env:
          name: ec2_tear-down-test-env
          filters: *filters
          requires:
            - ec2_test-update-service-job
            - ec2_tear-down-run-task-test
          aws-resource-name-prefix: ${AWS_RESOURCE_NAME_PREFIX_EC2}
          terraform-config-dir: "tests/terraform_setup/ec2"
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"

      #################
      # FargateSpot
      #################

      - test-fargatespot:
          context: [CPE-OIDC]
          filters: *filters
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
          requires:
            - fargate_set-up-test-env

      #################
      # CodeDeploy
      #################
      - build-test-app:
          name: codedeploy_fargate_build-test-app
          docker-image-namespace: "${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          docker-image-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}:${CIRCLE_SHA1}"
          context: [CPE-OIDC]
          filters: *filters
      - set-up-test-env:
          name: codedeploy_fargate_set-up-test-env
          filters: *filters
          requires:
            - codedeploy_fargate_build-test-app
          terraform-image: "hashicorp/terraform:1.1.9"
          aws-resource-name-prefix: ${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}
          terraform-config-dir: "tests/terraform_setup/fargate_codedeploy"
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST" 
      - test-service-update:
          name: codedeploy_fargate_test-update-service-command
          filters: *filters
          requires:
            - codedeploy_fargate_set-up-test-env
          aws-resource-name-prefix: ${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}
          family-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service"
          service-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service"
          docker-image-namespace: "${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          docker-image-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}:${CIRCLE_SHA1}"
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
          skip-service-update: true
          context: [CPE-OIDC]
      - aws-ecs/deploy-service-update:
          name: codedeploy_fargate_test-update-service-job
          docker-image-for-job: cimg/python:3.10.4
          filters: *filters
          requires:
            - codedeploy_fargate_test-update-service-command
          aws-region: AWS_REGION
          family: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service"
          cluster: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-cluster"
          container-image-name-updates: "container=${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service,image-and-tag=${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}:${CIRCLE_SHA1}"
          container-env-var-updates: 'container=${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service,name=VERSION_INFO,value="${CIRCLE_SHA1}_${CIRCLE_BUILD_NUM}",container=${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service,name=BUILD_DATE,value=$(date)'
          deployment-controller: "CODE_DEPLOY"
          codedeploy-application-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-codedeployapp"
          codedeploy-deployment-group-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-codedeploygroup"
          codedeploy-load-balanced-container-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service"
          codedeploy-load-balanced-container-port: 8080
          codedeploy-capacity-provider-name: "FARGATE"
          codedeploy-capacity-provider-base: "1"
          codedeploy-capacity-provider-weight: "2"
          verify-revision-is-deployed: false
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
          post-steps:
            - wait-for-codedeploy-deployment:
                application-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-codedeployapp"
                deployment-group-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-codedeploygroup"
            - test-deployment:
                service-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service"
                cluster: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-cluster"
                delete-load-balancer: false
      - aws-ecs/deploy-service-update:
          name: codedeploy_fargate_test-update-and-wait-service-job
          docker-image-for-job: cimg/python:3.10.4
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
          filters: *filters
          requires:
            - codedeploy_fargate_test-update-service-job
          aws-region: AWS_REGION
          family: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service"
          cluster: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-cluster"
          container-image-name-updates: "container=${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service,image-and-tag=${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}:${CIRCLE_SHA1}"
          container-env-var-updates: 'container=${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service,name=VERSION_INFO,value="${CIRCLE_SHA1}_${CIRCLE_BUILD_NUM}",container=${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service,name=BUILD_DATE,value=$(date)'
          deployment-controller: "CODE_DEPLOY"
          codedeploy-application-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-codedeployapp"
          codedeploy-deployment-group-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-codedeploygroup"
          codedeploy-load-balanced-container-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service"
          codedeploy-load-balanced-container-port: 8080
          verify-revision-is-deployed: true
          verification-timeout: "12m"
          post-steps:
            - test-deployment:
                service-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service"
                cluster: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-cluster"
                delete-load-balancer: true
            - delete-service:
                service-name: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-service"
                cluster: "${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}-cluster"
      - tear-down-test-env:
          name: codedeploy_fargate_tear-down-test-env
          requires:
            - codedeploy_fargate_test-update-and-wait-service-job
          terraform-image: "hashicorp/terraform:1.1.9"
          aws-resource-name-prefix: ${AWS_RESOURCE_NAME_PREFIX_CODEDEPLOY_FARGATE}
          terraform-config-dir: "tests/terraform_setup/fargate_codedeploy"
          context: [CPE-OIDC]
          role-arn: "arn:aws:iam::122211685980:role/CPE_ECS_OIDC_TEST"
          filters: *filters
      - orb-tools/pack:
          filters: *filters
      - orb-tools/publish:
          orb-name: circleci/aws-ecs
          vcs-type: << pipeline.project.type >>
          pub-type: production
          requires:
            - orb-tools/pack
            - ec2_tear-down-test-env
            - fargate_tear-down-test-env  
            - codedeploy_fargate_tear-down-test-env
            - integration-test-ecs-cli-install
          context: orb-publisher
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /^v[0-9]+\.[0-9]+\.[0-9]+$/
commands:
  wait-for-codedeploy-deployment:
    description: "Wait for the CodeDeploy deployment to be successful"
    parameters:
      application-name:
        description: "CodeDeploy application name"
        type: string
      deployment-group-name:
        description: "CodeDeploy application name"
        type: string
    steps:
      - run:
          name: Wait for CodeDeploy deployment to be successful (for orb testing and is not part of the orb)
          command: |
            DEPLOYMENT_ID=$(aws deploy list-deployments \
              --application-name << parameters.application-name >> \
              --deployment-group-name << parameters.deployment-group-name >> \
              --query "deployments" \
              --max-items 1 \
              --output text \
              | head -n 1)
            aws deploy wait deployment-successful --deployment-id ${DEPLOYMENT_ID}
  delete-service:
    description: "Forcefully delete an ECS service"
    parameters:
      service-name:
        description: "Name of the ECS service"
        type: string
      cluster:
        description: "Name of the cluster"
        type: string
    steps:
      - run:
          name: Delete ECS service
          command: |
            aws ecs delete-service \
              --cluster << parameters.cluster>> \
              --service << parameters.service-name >> \
              --force
  test-deployment:
    description: "Test the deployment"
    parameters:
      service-name:
        description: "Name of the ECS service"
        type: string
      cluster:
        description: "Name of the cluster"
        type: string
      test-asterisk-expansion:
        description: "Checks that asterisk expansion is prevented"
        type: boolean
        default: false
      delete-load-balancer:
        description: "Whether to delete the load balancer after the test"
        type: boolean
        default: false
    steps:
      - run:
          name: Test deployment (for orb testing and is not part of the orb)
          command: |-
            set -x
            TARGET_GROUP_ARN=$(aws ecs describe-services --cluster << parameters.cluster >> --services << parameters.service-name >> | jq -r '.services[0].loadBalancers[0].targetGroupArn')
            ELB_ARN=$(aws elbv2 describe-target-groups --target-group-arns $TARGET_GROUP_ARN | jq -r '.TargetGroups[0].LoadBalancerArns[0]')
            ELB_DNS_NAME=$(aws elbv2 describe-load-balancers --load-balancer-arns $ELB_ARN | jq -r '.LoadBalancers[0].DNSName')
            echo "ELB DNS NAME: $ELB_DNS_NAME"
            echo "Sleeping for one minute while waiting for AWS to come online."
            sleep 160s
            echo "Done sleeping"
            curl --retry 10 http://$ELB_DNS_NAME
            run_with_retry() {
              MAX_RETRY=6
              n=0
              until [ $n -ge $MAX_RETRY ]
              do
                # retry many times in case it takes a while for the new task definition to take effect
                curl -s --retry 10 http://$ELB_DNS_NAME \
                  | grep -E "Hello World\!.*${CIRCLE_SHA1}_${CIRCLE_BUILD_NUM}" <<#parameters.test-asterisk-expansion>> | grep "Asterisk \* expansion test"<</parameters.test-asterisk-expansion>> && break
                n=$[$n+1]
                sleep 60s
              done
              if [ $n -ge $MAX_RETRY ]; then
                echo "Error - Retry limit reached"
                exit 1
              fi
            }
            run_with_retry
            if [ "<< parameters.delete-load-balancer >>" == "1" ]; then
              aws elbv2 delete-load-balancer --load-balancer-arn $ELB_ARN
            fi
executors:
  mac:
    macos:
      xcode: 13.3.1
  linux:
    docker:
      - image: cimg/base:current
